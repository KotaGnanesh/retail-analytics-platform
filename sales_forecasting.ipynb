{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Sales Forecasting Analysis\n",
        "\n",
        "This notebook demonstrates multiple time series forecasting techniques for retail sales data:\n",
        "- **ARIMA**: Traditional autoregressive integrated moving average model\n",
        "- **Prophet**: Facebook's robust forecasting library for business time series\n",
        "- **XGBoost**: Machine learning approach for time series prediction\n",
        "\n",
        "## Business Objective\n",
        "Predict future sales to optimize inventory management, staffing, and marketing spend."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from datetime import datetime, timedelta\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "# Time series specific libraries\n",
        "# Note: Install these in your local environment:\n",
        "# pip install statsmodels prophet xgboost scikit-learn\n",
        "from statsmodels.tsa.arima.model import ARIMA\n",
        "from statsmodels.tsa.seasonal import seasonal_decompose\n",
        "from prophet import Prophet\n",
        "import xgboost as xgb\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Generate sample retail sales data\n",
        "def generate_sales_data():\n",
        "    \"\"\"\n",
        "    Generate synthetic retail sales data with seasonality and trends\n",
        "    \"\"\"\n",
        "    date_range = pd.date_range(start='2020-01-01', end='2023-12-31', freq='D')\n",
        "    n_days = len(date_range)\n",
        "    \n",
        "    # Base trend\n",
        "    trend = np.linspace(1000, 1500, n_days)\n",
        "    \n",
        "    # Seasonal patterns\n",
        "    yearly_seasonality = 200 * np.sin(2 * np.pi * np.arange(n_days) / 365.25)\n",
        "    weekly_seasonality = 100 * np.sin(2 * np.pi * np.arange(n_days) / 7)\n",
        "    \n",
        "    # Holiday spikes\n",
        "    holiday_boost = np.zeros(n_days)\n",
        "    for year in range(2020, 2024):\n",
        "        # Black Friday boost\n",
        "        black_friday = pd.Timestamp(f'{year}-11-25') + pd.Timedelta(days=(3-pd.Timestamp(f'{year}-11-25').weekday())%7)\n",
        "        if black_friday in date_range:\n",
        "            idx = date_range.get_loc(black_friday)\n",
        "            holiday_boost[idx-2:idx+3] += 500\n",
        "    \n",
        "    # Random noise\n",
        "    noise = np.random.normal(0, 50, n_days)\n",
        "    \n",
        "    # Combine components\n",
        "    sales = trend + yearly_seasonality + weekly_seasonality + holiday_boost + noise\n",
        "    sales = np.maximum(sales, 0)  # Ensure no negative sales\n",
        "    \n",
        "    return pd.DataFrame({\n",
        "        'date': date_range,\n",
        "        'sales': sales,\n",
        "        'day_of_week': date_range.day_name(),\n",
        "        'month': date_range.month,\n",
        "        'year': date_range.year\n",
        "    })\n",
        "\n",
        "# Generate and prepare data\n",
        "df = generate_sales_data()\n",
        "df.set_index('date', inplace=True)\n",
        "print(f\"Dataset shape: {df.shape}\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot time series\n",
        "plt.figure(figsize=(15, 10))\n",
        "\n",
        "# Main time series\n",
        "plt.subplot(2, 2, 1)\n",
        "plt.plot(df.index, df['sales'])\n",
        "plt.title('Daily Sales Over Time')\n",
        "plt.ylabel('Sales ($)')\n",
        "\n",
        "# Seasonal decomposition\n",
        "decomposition = seasonal_decompose(df['sales'], model='additive', period=365)\n",
        "\n",
        "plt.subplot(2, 2, 2)\n",
        "plt.plot(decomposition.trend)\n",
        "plt.title('Trend Component')\n",
        "plt.ylabel('Sales ($)')\n",
        "\n",
        "plt.subplot(2, 2, 3)\n",
        "plt.plot(decomposition.seasonal[:365])\n",
        "plt.title('Seasonal Component (1 Year)')\n",
        "plt.ylabel('Sales ($)')\n",
        "\n",
        "plt.subplot(2, 2, 4)\n",
        "plt.plot(decomposition.resid)\n",
        "plt.title('Residual Component')\n",
        "plt.ylabel('Sales ($)')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Summary statistics\n",
        "print(\"\\nSales Summary Statistics:\")\n",
        "print(df['sales'].describe())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 1: ARIMA Forecasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Split data for training and testing\n",
        "train_size = int(len(df) * 0.8)\n",
        "train_data = df['sales'][:train_size]\n",
        "test_data = df['sales'][train_size:]\n",
        "\n",
        "print(f\"Training period: {train_data.index[0]} to {train_data.index[-1]}\")\n",
        "print(f\"Testing period: {test_data.index[0]} to {test_data.index[-1]}\")\n",
        "\n",
        "# Fit ARIMA model\n",
        "# Note: In practice, use auto_arima for parameter optimization\n",
        "arima_model = ARIMA(train_data, order=(5, 1, 2))\n",
        "arima_fitted = arima_model.fit()\n",
        "\n",
        "# Generate forecasts\n",
        "arima_forecast = arima_fitted.forecast(steps=len(test_data))\n",
        "arima_forecast_df = pd.DataFrame({\n",
        "    'date': test_data.index,\n",
        "    'actual': test_data.values,\n",
        "    'forecast': arima_forecast\n",
        "})\n",
        "\n",
        "# Calculate metrics\n",
        "arima_mae = mean_absolute_error(test_data, arima_forecast)\n",
        "arima_rmse = np.sqrt(mean_squared_error(test_data, arima_forecast))\n",
        "\n",
        "print(f\"\\nARIMA Model Performance:\")\n",
        "print(f\"MAE: ${arima_mae:.2f}\")\n",
        "print(f\"RMSE: ${arima_rmse:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 2: Prophet Forecasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Prepare data for Prophet\n",
        "prophet_train = train_data.reset_index().rename(columns={'date': 'ds', 'sales': 'y'})\n",
        "prophet_test = test_data.reset_index().rename(columns={'date': 'ds', 'sales': 'y'})\n",
        "\n",
        "# Initialize and fit Prophet model\n",
        "prophet_model = Prophet(\n",
        "    daily_seasonality=True,\n",
        "    weekly_seasonality=True,\n",
        "    yearly_seasonality=True,\n",
        "    changepoint_prior_scale=0.05\n",
        ")\n",
        "\n",
        "# Add custom seasonalities for retail\n",
        "prophet_model.add_seasonality(name='monthly', period=30.5, fourier_order=5)\n",
        "\n",
        "prophet_model.fit(prophet_train)\n",
        "\n",
        "# Create future dataframe and predict\n",
        "future = prophet_model.make_future_dataframe(periods=len(test_data))\n",
        "prophet_forecast = prophet_model.predict(future)\n",
        "\n",
        "# Extract test period forecasts\n",
        "prophet_test_forecast = prophet_forecast.tail(len(test_data))['yhat'].values\n",
        "\n",
        "# Calculate metrics\n",
        "prophet_mae = mean_absolute_error(test_data, prophet_test_forecast)\n",
        "prophet_rmse = np.sqrt(mean_squared_error(test_data, prophet_test_forecast))\n",
        "\n",
        "print(f\"\\nProphet Model Performance:\")\n",
        "print(f\"MAE: ${prophet_mae:.2f}\")\n",
        "print(f\"RMSE: ${prophet_rmse:.2f}\")\n",
        "\n",
        "# Plot Prophet components\n",
        "fig = prophet_model.plot_components(prophet_forecast)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model 3: XGBoost Forecasting"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Feature engineering for XGBoost\n",
        "def create_features(data):\n",
        "    \"\"\"\n",
        "    Create time-based features for XGBoost\n",
        "    \"\"\"\n",
        "    df_features = data.copy()\n",
        "    \n",
        "    # Time-based features\n",
        "    df_features['day'] = df_features.index.day\n",
        "    df_features['month'] = df_features.index.month\n",
        "    df_features['year'] = df_features.index.year\n",
        "    df_features['dayofweek'] = df_features.index.dayofweek\n",
        "    df_features['quarter'] = df_features.index.quarter\n",
        "    df_features['dayofyear'] = df_features.index.dayofyear\n",
        "    \n",
        "    # Lag features\n",
        "    for lag in [1, 7, 14, 30]:\n",
        "        df_features[f'sales_lag_{lag}'] = df_features['sales'].shift(lag)\n",
        "    \n",
        "    # Rolling statistics\n",
        "    for window in [7, 14, 30]:\n",
        "        df_features[f'sales_rolling_mean_{window}'] = df_features['sales'].rolling(window=window).mean()\n",
        "        df_features[f'sales_rolling_std_{window}'] = df_features['sales'].rolling(window=window).std()\n",
        "    \n",
        "    # Weekend indicator\n",
        "    df_features['is_weekend'] = df_features['dayofweek'].isin([5, 6]).astype(int)\n",
        "    \n",
        "    return df_features.dropna()\n",
        "\n",
        "# Create features\n",
        "df_features = create_features(df)\n",
        "\n",
        "# Split with features\n",
        "train_size_xgb = int(len(df_features) * 0.8)\n",
        "X_train = df_features.drop('sales', axis=1)[:train_size_xgb]\n",
        "y_train = df_features['sales'][:train_size_xgb]\n",
        "X_test = df_features.drop('sales', axis=1)[train_size_xgb:]\n",
        "y_test = df_features['sales'][train_size_xgb:]\n",
        "\n",
        "# Train XGBoost model\n",
        "xgb_model = xgb.XGBRegressor(\n",
        "    n_estimators=100,\n",
        "    max_depth=6,\n",
        "    learning_rate=0.1,\n",
        "    random_state=42\n",
        ")\n",
        "\n",
        "xgb_model.fit(X_train, y_train)\n",
        "\n",
        "# Generate predictions\n",
        "xgb_forecast = xgb_model.predict(X_test)\n",
        "\n",
        "# Calculate metrics\n",
        "xgb_mae = mean_absolute_error(y_test, xgb_forecast)\n",
        "xgb_rmse = np.sqrt(mean_squared_error(y_test, xgb_forecast))\n",
        "\n",
        "print(f\"\\nXGBoost Model Performance:\")\n",
        "print(f\"MAE: ${xgb_mae:.2f}\")\n",
        "print(f\"RMSE: ${xgb_rmse:.2f}\")\n",
        "\n",
        "# Feature importance\n",
        "feature_importance = pd.DataFrame({\n",
        "    'feature': X_train.columns,\n",
        "    'importance': xgb_model.feature_importances_\n",
        "}).sort_values('importance', ascending=False)\n",
        "\n",
        "print(\"\\nTop 10 Most Important Features:\")\n",
        "print(feature_importance.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Model Comparison and Visualization"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Compare all models\n",
        "comparison_results = pd.DataFrame({\n",
        "    'Model': ['ARIMA', 'Prophet', 'XGBoost'],\n",
        "    'MAE': [arima_mae, prophet_mae, xgb_mae],\n",
        "    'RMSE': [arima_rmse, prophet_rmse, xgb_rmse]\n",
        "})\n",
        "\n",
        "print(\"Model Performance Comparison:\")\n",
        "print(comparison_results)\n",
        "\n",
        "# Visualization\n",
        "plt.figure(figsize=(15, 8))\n",
        "plt.plot(test_data.index, test_data.values, label='Actual Sales', linewidth=2)\n",
        "plt.plot(test_data.index, arima_forecast, label='ARIMA Forecast', alpha=0.7)\n",
        "plt.plot(test_data.index, prophet_test_forecast, label='Prophet Forecast', alpha=0.7)\n",
        "plt.plot(y_test.index, xgb_forecast, label='XGBoost Forecast', alpha=0.7)\n",
        "\n",
        "plt.title('Sales Forecasting Model Comparison')\n",
        "plt.xlabel('Date')\n",
        "plt.ylabel('Sales ($)')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "# Generate 30-day forecast with best model\n",
        "best_model_name = comparison_results.loc[comparison_results['MAE'].idxmin(), 'Model']\n",
        "print(f\"\\nBest performing model: {best_model_name}\")\n",
        "\n",
        "# Future forecast (using Prophet for example)\n",
        "future_30_days = prophet_model.make_future_dataframe(periods=30)\n",
        "future_forecast = prophet_model.predict(future_30_days)\n",
        "next_30_days = future_forecast.tail(30)[['ds', 'yhat', 'yhat_lower', 'yhat_upper']]\n",
        "\n",
        "print(\"\\n30-Day Sales Forecast:\")\n",
        "print(next_30_days.head(10))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Business Recommendations\n",
        "\n",
        "Based on the forecasting analysis:\n",
        "\n",
        "1. **Inventory Planning**: Use 30-day forecasts to optimize stock levels\n",
        "2. **Staffing**: Align workforce with predicted demand patterns\n",
        "3. **Marketing Budget**: Allocate spending based on forecasted sales periods\n",
        "4. **Model Monitoring**: Retrain models monthly with new data"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}